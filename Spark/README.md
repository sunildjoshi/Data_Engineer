# **Project: Data Lake Spark**

# Introduction
Sparkify a music streaming startup wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs users are listening to. Currently the data resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

In this project a star schema for database schema, designed for optimizing queries on song play analysis. In this project we will develop ETL pipeline for this analysis.

Two datasets that reside in S3. The S3 links for each:

- Song data: s3://udacity-dend/song_data
- Log data: s3://udacity-dend/log_data

JSON PATH
- Log data json path: s3://udacity-dend/log_json_path.json

## Song Dataset
The first dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song.
    
## Log Dataset
The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate app activity logs from an imaginary music streaming app based on configuration settings.

# Database schema design and ETL pipeline.

## From this representation we can already start to see the makings of a "STAR". We have one fact table (the center of the star) and 4  dimension tables that are coming from it.

### Fact Table
`Table Name: songplays, Description: records in log data associated with song plays
column: songplay_id
column: start_time
column: user_id
column: level
column: song_id
column: artist_id
column: session_id
column: location
column: user_agent
column: year
column: month`

### Dimension Tables

`Table Name: users, Description: users in the app
column: user_id
column: first_name
column: last_name
column: gender
column: level`

`Table Name: songs, Description: songs in music database
column: song_id
column: title
column: artist_id
column: year
column: duration`

`Table Name: artists, Description: artists in music database
column: artist_id
column: name
column: location
column: latitude 
column: longitude`

`Table Name: time, Description: timestamps of records in songplays broken down into specific units
column: start_time
column: hour
column: day
column: week
column: month
column: year
column: weekday`

## Star schema makes easy for business sense it will reduce the need for joining and easy to understand.

-Denormalized

-Fast aggregation

-Simplified queries


## Instruction to run the script or Notebook

- submit python script `etl.py` on spark cluster by updating AWS_KEY_ID and AWS_SECRET_ACCESS_KEY in config file dl.cfg

- Run all cells of notebook `Demo.ipynb`